---
title: "Cachable OSCORE"
docname: draft-amsuess-core-cachable-oscore-latest
ipr: trust200902
stand_alone: true
cat: exp
wg: CoRE
kw: CoAP, OSCORE, multicast, caching, proxy
author:
- ins: C. Amsüss
  name: Christian Amsüss
  country: Austria
  email: christian@amsuess.com
-
  ins: M. Tiloca
  name: Marco Tiloca
  org: RISE AB
  street: Isafjordsgatan 22
  city: Kista
  code: SE-16440 Stockholm
  country: Sweden
  email: marco.tiloca@ri.se
normative:
informative:

--- abstract

OSCORE group communication can secure CoAP group communication across untrusted proxies,
but in doing so sidesteps the proxies' caching abilities.
This restores cachability of requests by introducing consensus requests which any client in a group can send.

--- middle

# Introduction {#introduction}

With OSCORE group communication,
requests and responses can be read by other group members can be read by any group member as long as pairwise mode is not used.
While this can populate a proxy's cache if the proxy is a member of the group,
and the proxy can use the cache to respond if is recognized by the client as an eligible server,
untrusted proxies only see opaque uncachable ciphertext.

This document introduces cachability in responses in two stages,
initially building on concepts developed in {{!I-D.tiloca-core-observe-multicast-notifications}}.
Caching is thus enabled for proxies that are not members of the OSCORE group,
and are unaware of OSCORE in general.
Allowing them to cache requests is traded against some request privacy:
For clients that participate in this scheme,
the proxy (and any other party that can read the network traffic)
can see which clients request the same resource,
and how the resource's representation changes in size over time.

As in {{!I-D.tiloca-core-observe-multicast-notifications}},
clients and servers are assumed to already be members of a suitable OSCORE group.

## Procedural Status

\[

This is an early idea that would bring back some concepts to OSCORE that were present as OSCON in its early drafts.

The main purpose of publishing the draft at this stage is to fathom whether the concept of a deterministic client has a chance of living up the standards of the IETF community (no pun intended).

\]

# Terminology

The reader is expected to be familiar with the terms of {{!I-D.ietf-core-oscore-groupcomm}}.

This document introduces the following new terms:

Consensus Request

: A Group OSCORE request that can be used repeatedly to access a particular resource.
: It has all the properties relevant to caching, but its transport dependent properties (e.g. Token or Message ID) are not defined.
: Thus, different requests on the wire can both be said to "be the Consensus Request" even if they have different tokens or client addresses.
:
: As the consensus request is the reference for request-response binding,
: the client always needs to be able to read and verify any Consensus Request it receives before using it to verify a response.

Ticket Request

: A Consensus Request generated by the server itself.
: The Phantom Request of {{!I-D.tiloca-core-observe-multicast-notifications}} is the prototypical Ticket Request.

Deterministic Client

: A fictious member of an OSCORE group with no Sender Sequence Number and no Recipient Context.
: The Deterministic Client is set up in the group manager,
: has only the minimum common set of privileges shared by all group members.

Deterministic Request

: A Consensus Request generated by the Deterministic Client.

# Simple Cachability using Ticket Requests

Building on phantom requests and informative responses of {{!I-D.tiloca-core-observe-multicast-notifications}},
basic proxying operation is already possible with the mechanisms described there:

A server can, instead of sending a regular response,
send an informative response, which is a protected 5.03 error message
whose payload contains the phantom request (which is a Ticket Request in this document's broader terminology).

Even though the request is not necessarily an observe request,
the server picks FETCH as the outer code of the request in order to make the request cachable.

The client verifies that the ticket request is indeed equivalent to its original request,
and -- and this is where the process starts to deviate from multicast notifications -- sends the ticket request to the server through the proxy.

As with multicast notifications, this check especially verifies that the request URI, including protocol and host name,
is identical between the original and the Ticket Request.
Any difference there would indicate URI aliasing, which is not allowed initially.

When the server receives the ticket request, it produces a regular response,
but puts a non-zero Max-Age option as an outer option.
(There is no point in putting in an inner Max-Age option, as the client could not pin it in time).

When another client later asks for the same resource,
its new request produces a cache miss at the proxy (as it uses a different KID and Partial IV),
but the server responds with the same Ticket Request.
The Ticket Request can then be served from the proxy's cache.

When multiple proxies are in use,
or the response was expires from the proxy's cache,
the server will receive the Ticket Request multiple times.
It is a matter of perspective whether it treats that as an acceptable replay
(given that this whole mechansim only makes sense on side effect free requests),
or whether it is conceptualized as having an internal proxy where the request produces a cache hit.

## Usefullness

As all clients' requests produce an initial cache miss and thus hit the origin server,
the caching benefits of such an approach are limited to two cases:

* observations (where this can be used to set up multicast notifications through proxies), and
* large representations that are use outer block-wise mode (which are probably rare compared to inner block-wise mode).

For any other case, the benefit of caching a single response of only up to 1kB in size
is probably outweighed by the necessity to have an additional round trip,
or at least drastically reduces the gains.

The mechanism could probably be extended to work for inner block-wise as well
(by introducing an option by which the server sends the next-block Ticket Request along with the response).
However, there has to be a better way...

# Deterministic Requests

This section introduces a method of arriving at a Consensus Request inside the client:
Rather than relying on the server to decree a Token Request,
clients build their request in as reproducible a fashion as possible
(where some disagreement might be eventually unavoidable,
but won't have more severe a consequence than two requests for the same resource occupying space in the caches).

The hard part is arriving at a consensus nonce,
while avoiding nonce reuse.

A suitable nonce can conceptually be produced by applying a cryptographic hash function to the complete input of the encryption operation,
which is the plaintrext of the COSE object and the AAD.

No particular hashing mechanism is recommended so far,
but any non-malleable cryptographically secure hash should do,
and malleable hashes could be permitted if the input material were adaequately encapsulated before hashing.

As the 40 bit available in the nonce are by far insufficient to ensure that the deterministic client's nonce is not reused,
(even if the full nonce and not only partial IV could be set, the common algorithms' nonces would still be too short),
the hash has to be fed into the key generation rather than the encyption's nonce
in a new mechanism.

A positive side effect of not transporting that information in the OSCORE nonce crops up with versions of oscore-groupcomm starting at -11:
With the full encoded OSCORE option becoming part of the AAD,
there would be a circular dependency from feeding the AAD into the hash,
which needs crude workarounds like building the full AAD twice,
or zeroing out the hash-to-be.

## Request-Hash

A new CoAP option is defined called Request-Hash.

It is identical in all its properties to Request-Tag, except that

* It may be arbitrarily long.
* A proxy MAY use any fresh cached response from the selected server to respond to a request with the same Request-Hash
  (or possibly even if the new request's Request-Hash is a prefix of the cached one).

  This is a potential future optimization that is not mentioned anywhere else yet,
  and allows clients to elide all other options and payload if it has reason to believe that it can produce a cache hit
  with the abbreviated request alone.

* With OSCORE, as the option is created at message protection time (and used before unprotection), it is treated as Class U
  when used with a deterministic client.

  Other uses can put it into different categories.

The suggested option number for this option is 548.

## Use of Deterministic Requests

A client that sends a request for which it hopes to get a cached response
can ask the group manager for the key details of the Deterministic Client.
(Conceptionally, there can be multiple deterministic clients in a group,
e.g. to allow freshness indications without rekeying the whole group;
a query for "the" deterministic client would typically return the latest).
This needs to be a feature implemented by the group manager protocol,
and the response differs from regular responses from the GM in that there is no public key associated with that member,
but a hash function instead.

The client creates its request in pairwise mode,
indicating the deterministic client's sender ID as its own sender ID,
with the following alterations:

* The Partial IV is set to 0 for all requests; it does not need to be set in the OSCORE option.
* The key derivation for the sender key is postponed to the point where the plaintext and AAD are ready.
* The hash function indicated for the deterministic client is applied to the concatenation of AAD and plaintext.
  Note that the payload is not self-delimiting, and thus hash functions are limited to non-malleable ones.
* In the key derivation for the pairwise sender key, the shared secret
  (which can not be obtained as there is no public key associated with the deterministic client)
  is replaced with the obtained hash.
* The hash is put in an Request-Hash option of the protected request.
* It uses FETCH as the outer code to make it cachable, even if no observation is requested.

As the key is derived using material from the whole request, this key/nonce pair is only used for this very message
and deterministically encrypted
unless there is a hash collision between two deterministic requests.
The deterministic encryption requires that the used AEAD scheme be deterministic in itself.
Those currently registered with COSE are; for future ones, a flag in the registry is to be added.

Note that while being based on the pairwise mechanism, no information about the server has become part of the key derivation or AAD;
this is intentional (as it opens up the path to deterministic requests to multicast addresses),
and necessitates the later check at response unprotection.

When the server processes such a request,
it obtains the client's pairwise data from the GM,
seeing there is no actual public key and that it's a deterministic client.
(If it does not support deterministic encryption,
it can not process that information, will fail to crete a recipient context, and fail the request).

It then derives a recipient context based on the hash in the Request-Hash option,
and unprotects the message using that context.

If unprotection passed, there are additional processing requirements on the server:
* It MUST perform the same hashing as the client, and MUST treat the request as invalid if the hash does not match the Request-Hash.
  Failure to do so would enable an attacker that guessed a good authentication tag for a given Request-Hash
  to poison caches with incorrect responses.
* If MUST verify that the unprotected message is safe to be processed in the REST sense (i.e. it has no side effects).
  Note that on CoAP implementations that can not prevent that an application produces side effects from a safe request,
  this may incur checking whether the particular handler is marked as side-effect free.
  An implementation may also have a configured list of requests that are known to be side effect free,
  and reject any other request.
  Failure at this stage SHOULD result in a protected 4.01 Unauthorized response.
* The server MUST respond in group mode
  (for otherwise the client can not get source authentication, given the "pairwise" key is actually shared among all the group),
  and send an own Partial IV
  (for it does not perform replay protection, see below).

These checks replace the otherwise present requirement that the server needs to check the recipient context's replay window,
which is inapplicable with the recipient context it derived based on the Request-Hash.
The reasoning is analogous to the one in {{?I-D.amsuess-lwig-oscore}} to treat the potential replay as answerable
if the request is side effect free.

Both in protecting and unprotecting the response,
the `request_kid` field of the external AAD is replaced with the Request-Hash value.
This creates the request-response binding that ensures no mismatched responses can be successfully unprotected.

[ Mismatching this with the request's `request_kid` (that stays the deterministic client's ID) is ugly,
  but also the only way to avoid any zeroing / rebuilding.
  I suggest for any OSCORE v2 that request details be not present in the request's AAD,
  and that rather than kid, piv and (in group mode) kid-context being separate fields,
  they be something more pluggable. ]

By setting a non-zero Max-Age option,
the server makes the request usable for the proxy cache.

The client, receiving the response,
verifies the signature based on the KID of the server it sent the request to,
and unprotects the message.

The client MUST verify that the KID the server sent is the intended one,
unless it expects responses from multiple servers.

### Deterministic Requests Used With Groups

A Deterministic Request *can* be sent to a CoAP group;
it is still created the same way as a pairwise request to simplify key derivation.
(If it were a group request, the hash would need to be fed into the group key derivation just for this corner case;
furthermore, there'd need to be a signature from the absent public key).

When a server receives a request from the Deterministic Client that was addressed to a CoAP group,
it MUST send its KID with the response (even though that is usually not a requirement when responding to a pairwise request).

# Open questions

* Can the informative response be unprotected?

  Otherwise, how would a proxy forwarding the Ticket Request to a multicast-notification network learn the relevant token?

  (The client shouldn't really trust the server's statement about the requests' equivalence anyway).

* Is "deterministic encryption" something worthwhile to consider in COSE?

  COSE would probably specify something more elaborate for the KDF
  (the current KDF round is the pairwise mode's;
  COSE would probably run through KDF with a KDF context structure).

  COSE would give a header parameter name to the Request-Hash
  (which for the purpose of OSCORE deterministic requests would put back into Request-Hash by extending the option compression function across the two options).

  Conceptually, they should align well, and the implementation changes are likely limited to how the KDF is run.

# Unsorted further ideas

* All or none of the deterministic requests should have an inner observe option.
  Preferably none -- that makes messages shorter, and clients need to ignore that option either way when checking whether a Consensus Request matches their intended request.

* An outer ETag does make sense here; an easy value for the server is the response Partial IV.

--- back

<!--
# Change log

Since -00:
-->

# Padding

In order to hide information that can be leaked by the length of a response (or, in different contexts, a request),
the following padding option is defined to allow adding to a message's length without changing its meaning.

It can be used with any CoAP transport,
but is especially useful with OSCORE as that does provide any padding of its own.

Before chosing to pad a message by the Padding option,
application designers should consider whether they can arrange for common message variants to have the same length
by picking a suitable content representation;
the canonical example here is expressing "yes" and "no" with "y" and "n", respectively.

## Definition of the Padding option

~~~
   +------+---+---+---+---+----------------+--------+--------+---------+
   | No.  | C | U | N | R | Name           | Format | Length | Default |
   +------+---+---+---+---+----------------+--------+--------+---------+
   | TBDH |   |   | x | x | Padding        | opaque | any    | (none)  |
   +------+---+---+---+---+----------------+--------+--------+---------+
~~~

The Padding option is elective, safe to forward and not part of the cache key;
these follow from the usage instructions.

It may be repeated, as repeated option may be the only way to get certain lengths.

The option number is picked to be the highest number in the Experts Review range;
the high option number allows it to follow practically all other options,
and thus to be set when the final unpadded message length including all options
is known.

\[ Therefore, the number suggested to IANA is 64988. TBD: move this into IANA considerations. \]

Applications that make use of the "Experimental use" range and want to preserve that property
are invited to pick the largest suitable experimental number (65532)

Note that unless other high options are used, this means that padding a message adds an overhead of at least 3 bytes
(option delta/length byte and two bytes of extended option length).
This is considered acceptable overhead,
given that the application already chose to prefer the privacy gains of padding over wire transfer length.

## Using and processing the Padding option

Any client may set the Padding option, at any length, with any content.

A server MUST ignore the option.

Proxies are free to keep the Padding option on a message,
to remove it or to add own padding.

\[ TBD:  reference back in text as mitigation for size leak \]

# Acknowledgments # {#acknowldegment}
{: numbered="no"}

The authors sincerely thank Jim Schaad for his comments and feedback.

The work on this document has been partly supported by VINNOVA and the Celtic-Next project CRITISEC; and by the H2020 project SIFIS-Home (Grant agreement 952652).
